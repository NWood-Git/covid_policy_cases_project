{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "org_df_policy = pd.read_csv ('usa-covid-policy/data/OxCGRT_US_latest.csv')\n",
    "org_jhu_deaths_df = pd.read_csv('csse_covid_19_time_series/time_series_covid19_deaths_US.csv')\n",
    "org_jhu_cases_df = pd.read_csv('csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxford Policy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionCode</th>\n",
       "      <th>Jurisdiction</th>\n",
       "      <th>Date</th>\n",
       "      <th>C1_School closing</th>\n",
       "      <th>C1_Flag</th>\n",
       "      <th>C1_Notes</th>\n",
       "      <th>C2_Workplace closing</th>\n",
       "      <th>...</th>\n",
       "      <th>StringencyIndex</th>\n",
       "      <th>StringencyIndexForDisplay</th>\n",
       "      <th>StringencyLegacyIndex</th>\n",
       "      <th>StringencyLegacyIndexForDisplay</th>\n",
       "      <th>GovernmentResponseIndex</th>\n",
       "      <th>GovernmentResponseIndexForDisplay</th>\n",
       "      <th>ContainmentHealthIndex</th>\n",
       "      <th>ContainmentHealthIndexForDisplay</th>\n",
       "      <th>EconomicSupportIndex</th>\n",
       "      <th>EconomicSupportIndexForDisplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAT_GOV</td>\n",
       "      <td>20200101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAT_GOV</td>\n",
       "      <td>20200101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAT_GOV</td>\n",
       "      <td>20200102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAT_GOV</td>\n",
       "      <td>20200102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAT_GOV</td>\n",
       "      <td>20200103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16249</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US_WY</td>\n",
       "      <td>STATE_ALL</td>\n",
       "      <td>20201023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US_WY</td>\n",
       "      <td>STATE_ALL</td>\n",
       "      <td>20201024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16251</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US_WY</td>\n",
       "      <td>STATE_ALL</td>\n",
       "      <td>20201025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16252</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US_WY</td>\n",
       "      <td>STATE_ALL</td>\n",
       "      <td>20201026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16253</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US_WY</td>\n",
       "      <td>STATE_ALL</td>\n",
       "      <td>20201027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16254 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CountryName CountryCode RegionName RegionCode Jurisdiction      Date  \\\n",
       "0      United States         USA        NaN        NaN      NAT_GOV  20200101   \n",
       "1      United States         USA        NaN        NaN      NAT_GOV  20200101   \n",
       "2      United States         USA        NaN        NaN      NAT_GOV  20200102   \n",
       "3      United States         USA        NaN        NaN      NAT_GOV  20200102   \n",
       "4      United States         USA        NaN        NaN      NAT_GOV  20200103   \n",
       "...              ...         ...        ...        ...          ...       ...   \n",
       "16249  United States         USA    Wyoming      US_WY    STATE_ALL  20201023   \n",
       "16250  United States         USA    Wyoming      US_WY    STATE_ALL  20201024   \n",
       "16251  United States         USA    Wyoming      US_WY    STATE_ALL  20201025   \n",
       "16252  United States         USA    Wyoming      US_WY    STATE_ALL  20201026   \n",
       "16253  United States         USA    Wyoming      US_WY    STATE_ALL  20201027   \n",
       "\n",
       "       C1_School closing  C1_Flag C1_Notes  C2_Workplace closing  ...  \\\n",
       "0                    0.0      NaN      NaN                   0.0  ...   \n",
       "1                    NaN      NaN      NaN                   NaN  ...   \n",
       "2                    0.0      NaN      NaN                   0.0  ...   \n",
       "3                    NaN      NaN      NaN                   NaN  ...   \n",
       "4                    0.0      NaN      NaN                   0.0  ...   \n",
       "...                  ...      ...      ...                   ...  ...   \n",
       "16249                NaN      NaN      NaN                   NaN  ...   \n",
       "16250                NaN      NaN      NaN                   NaN  ...   \n",
       "16251                NaN      NaN      NaN                   NaN  ...   \n",
       "16252                NaN      NaN      NaN                   NaN  ...   \n",
       "16253                NaN      NaN      NaN                   NaN  ...   \n",
       "\n",
       "       StringencyIndex StringencyIndexForDisplay  StringencyLegacyIndex  \\\n",
       "0                  0.0                      0.00                    0.0   \n",
       "1                  NaN                       NaN                    NaN   \n",
       "2                  0.0                      0.00                    0.0   \n",
       "3                  NaN                       NaN                    NaN   \n",
       "4                  0.0                      0.00                    0.0   \n",
       "...                ...                       ...                    ...   \n",
       "16249              NaN                     40.74                    NaN   \n",
       "16250              NaN                     40.74                    NaN   \n",
       "16251              NaN                     40.74                    NaN   \n",
       "16252              NaN                     40.74                    NaN   \n",
       "16253              NaN                     40.74                    NaN   \n",
       "\n",
       "       StringencyLegacyIndexForDisplay GovernmentResponseIndex  \\\n",
       "0                                 0.00                     0.0   \n",
       "1                                  NaN                     NaN   \n",
       "2                                 0.00                     0.0   \n",
       "3                                  NaN                     NaN   \n",
       "4                                 0.00                     0.0   \n",
       "...                                ...                     ...   \n",
       "16249                            49.52                     NaN   \n",
       "16250                            49.52                     NaN   \n",
       "16251                            49.52                     NaN   \n",
       "16252                            49.52                     NaN   \n",
       "16253                            49.52                     NaN   \n",
       "\n",
       "       GovernmentResponseIndexForDisplay  ContainmentHealthIndex  \\\n",
       "0                                   0.00                     0.0   \n",
       "1                                    NaN                     NaN   \n",
       "2                                   0.00                     0.0   \n",
       "3                                    NaN                     NaN   \n",
       "4                                   0.00                     0.0   \n",
       "...                                  ...                     ...   \n",
       "16249                              45.24                     NaN   \n",
       "16250                              45.24                     NaN   \n",
       "16251                              45.24                     NaN   \n",
       "16252                              45.24                     NaN   \n",
       "16253                              45.24                     NaN   \n",
       "\n",
       "      ContainmentHealthIndexForDisplay  EconomicSupportIndex  \\\n",
       "0                                 0.00                   0.0   \n",
       "1                                  NaN                   NaN   \n",
       "2                                 0.00                   0.0   \n",
       "3                                  NaN                   NaN   \n",
       "4                                 0.00                   0.0   \n",
       "...                                ...                   ...   \n",
       "16249                            48.61                   NaN   \n",
       "16250                            48.61                   NaN   \n",
       "16251                            48.61                   NaN   \n",
       "16252                            48.61                   NaN   \n",
       "16253                            48.61                   NaN   \n",
       "\n",
       "       EconomicSupportIndexForDisplay  \n",
       "0                                 0.0  \n",
       "1                                 NaN  \n",
       "2                                 0.0  \n",
       "3                                 NaN  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "16249                            25.0  \n",
       "16250                            25.0  \n",
       "16251                            25.0  \n",
       "16252                            25.0  \n",
       "16253                            25.0  \n",
       "\n",
       "[16254 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_df_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy = org_df_policy[[\"Date\", \"RegionCode\", \"RegionName\", \"CountryCode\", \"Jurisdiction\", \"StringencyIndexForDisplay\",\n",
    "                           \"GovernmentResponseIndexForDisplay\", \"ContainmentHealthIndexForDisplay\",\n",
    "                           \"EconomicSupportIndexForDisplay\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/.local/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df_policy.Jurisdiction.unique()\n",
    "# Removing rows where the Jurisdiction is NAT_GOV since I only want to look at the states\n",
    "nat_gov_jur = df_policy[df_policy[\"Jurisdiction\"] == \"NAT_GOV\"].index\n",
    "df_policy.drop(nat_gov_jur, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0220f3b0c3da>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_policy[col] /= 100\n"
     ]
    }
   ],
   "source": [
    "# Normalize the Indicies Columns using the max for each col.\n",
    "indices = df_policy.filter(regex=\"Index\")\n",
    "for col in indices.columns:\n",
    "    df_policy[col] /= 100\n",
    "\n",
    "# Each index is composed of a series of individual policy response indicators. For each\n",
    "# indicator, we create a score by taking the ordinal value and adding an extra half-point\n",
    "# if the policy is general rather than targeted, if applicable. We then rescale each of\n",
    "# these by their maximum value to create a score between 0 and 100, with a missing\n",
    "# value contributing 0.5 These scores are then averaged to get the composite indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Run Once\n",
    "df_policy = df_policy.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy = df_policy[df_policy['Date'] >= 20200122]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy['Date'] = pd.to_datetime(df_policy['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_in_policy = set(df_policy['RegionName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_policy = df_policy.drop(['RegionCode', 'Jurisdiction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell replaces all Nan Values where the previous value == the next valid value \n",
    "# for the specified column - the Nan is replaced with the prev value\n",
    "df_policy.loc[df_policy['StringencyIndexForDisplay'].ffill() == \n",
    "              df_policy['StringencyIndexForDisplay'].bfill(),\n",
    "              'StringencyIndexForDisplay'] = df_policy['StringencyIndexForDisplay'].ffill()\n",
    "\n",
    "df_policy.loc[df_policy['GovernmentResponseIndexForDisplay'].ffill() == \n",
    "              df_policy['GovernmentResponseIndexForDisplay'].bfill(),\n",
    "              'GovernmentResponseIndexForDisplay'] = df_policy['GovernmentResponseIndexForDisplay'].ffill()\n",
    "\n",
    "df_policy.loc[df_policy['ContainmentHealthIndexForDisplay'].ffill() == \n",
    "              df_policy['ContainmentHealthIndexForDisplay'].bfill(),\n",
    "              'ContainmentHealthIndexForDisplay'] = df_policy['ContainmentHealthIndexForDisplay'].ffill()\n",
    "\n",
    "df_policy.loc[df_policy['EconomicSupportIndexForDisplay'].ffill() == \n",
    "              df_policy['EconomicSupportIndexForDisplay'].bfill(),\n",
    "              'EconomicSupportIndexForDisplay'] = df_policy['EconomicSupportIndexForDisplay'].ffill()\n",
    "\n",
    "# Old code\n",
    "# The following line are checking the EconomicSupportIndexForDisplay data for Idaho as\n",
    "# There seems to be a NaN at 9/1 that is a one off - the surrounding numbers are zero so I will make it 0.\n",
    "# y = df_policy.loc[(df_policy['RegionName']=='Idaho') & (df_policy['Date'] >= pd.Timestamp(2020,8,30))]\n",
    "\n",
    "# The below line changes the value - for Idaho EconomicSupportIndexForDisplay on 9/1/2020 to zero\n",
    "# df_policy.loc[(df_policy['RegionName']=='Idaho') &\n",
    "#               (df_policy['Date'] == pd.Timestamp(2020,9,1)),'EconomicSupportIndexForDisplay'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>StringencyIndexForDisplay</th>\n",
       "      <th>GovernmentResponseIndexForDisplay</th>\n",
       "      <th>ContainmentHealthIndexForDisplay</th>\n",
       "      <th>EconomicSupportIndexForDisplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, RegionName, CountryCode, StringencyIndexForDisplay, GovernmentResponseIndexForDisplay, ContainmentHealthIndexForDisplay, EconomicSupportIndexForDisplay]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking there are no nulls in df_policy\n",
    "null_policy = df_policy[df_policy.isnull().any(axis=1)]\n",
    "null_policy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JHU Data: Covid-19 Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Run Once\n",
    "df_deaths_jhu = org_jhu_deaths_df.groupby('Province_State').sum()\n",
    "df_deaths_jhu = df_deaths_jhu.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Run Once\n",
    "df_deaths_jhu['Province_State'].replace({\"District of Columbia\": \"Washington DC\"}, inplace=True)\n",
    "states_in_df_deaths = set(df_deaths_jhu['Province_State'])\n",
    "\n",
    "# everything in policy df is in deaths df - this sees what in deaths df but not in policy\n",
    "diff_states = states_in_df_deaths.difference(states_in_policy)\n",
    "rows_to_remove = df_deaths_jhu[df_deaths_jhu['Province_State'].isin(diff_states)].index\n",
    "df_deaths_jhu.drop(rows_to_remove, inplace=True)\n",
    "df_deaths_jhu = df_deaths_jhu.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_population = df_deaths_jhu[['Province_State', 'Population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths_jhu = df_deaths_jhu.drop(['index','UID', 'code3', 'FIPS', 'Lat', 'Long_', 'Population'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = list(df_deaths_jhu.columns)[1:] # index 0 has the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_deaths_df = df_deaths_jhu.copy()\n",
    "deaths_df = pd.DataFrame(columns=('Date', 'State', 'Deaths Per Capita'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This cell takes a little while to run approx 48.62 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in temp_deaths_df.iterrows():\n",
    "    for date in date_list:\n",
    "        state = row['Province_State']\n",
    "        new_row = pd.Series({'Date':date, 'State':state,\n",
    "                             'Deaths Per Capita':row[date] / \n",
    "                             int(state_population[state_population['Province_State'] == state]['Population'])})\n",
    "        deaths_df = deaths_df.append(new_row, ignore_index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JHU Data: Covid-19 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Run Once\n",
    "df_cases_jhu = org_jhu_cases_df.groupby('Province_State').sum()\n",
    "df_cases_jhu = df_cases_jhu.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Run Once\n",
    "df_cases_jhu['Province_State'].replace({\"District of Columbia\": \"Washington DC\"}, inplace=True)\n",
    "states_in_df_cases = set(df_cases_jhu['Province_State'])\n",
    "\n",
    "rows_to_remove = df_cases_jhu[df_cases_jhu['Province_State'].isin(diff_states)].index\n",
    "df_cases_jhu.drop(rows_to_remove, inplace=True)\n",
    "df_cases_jhu = df_cases_jhu.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cases_df = df_cases_jhu.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This cell takes a little while to run approx 47.93 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_df = pd.DataFrame(columns=('Date', 'State', 'Cases Per Capita'))\n",
    "for index, row in temp_cases_df.iterrows():\n",
    "    for date in date_list:\n",
    "        state = row['Province_State']\n",
    "        new_row = pd.Series({'Date':date, 'State':state,\n",
    "                             'Cases Per Capita': row[date] /\n",
    "                              int(state_population[state_population['Province_State'] == state]['Population'])})\n",
    "        cases_df = cases_df.append(new_row, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# deaths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_and_cases_df = pd.merge(deaths_df, cases_df,  how='left', left_on=['Date','State'], \n",
    "                            right_on = ['Date','State'])\n",
    "deaths_and_cases_df['Date'] = pd.to_datetime(deaths_and_cases_df['Date'], format='%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deaths_and_cases_df ends at 10/26 while df_policy ends at 10/27\n",
    "# Here we are setting restrictingt the dates of df_policy to be stop at the max date of deaths_and_cases_df\n",
    "df_policy = df_policy[df_policy['Date'] <=  deaths_and_cases_df['Date'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_policy) == len(deaths_and_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_combined_df = pd.merge(deaths_and_cases_df, df_policy, how='inner',\n",
    "                               left_on=['Date', 'State'], right_on=['Date', 'RegionName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Deaths Per Capita</th>\n",
       "      <th>Cases Per Capita</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>StringencyIndexForDisplay</th>\n",
       "      <th>GovernmentResponseIndexForDisplay</th>\n",
       "      <th>ContainmentHealthIndexForDisplay</th>\n",
       "      <th>EconomicSupportIndexForDisplay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, State, Deaths Per Capita, Cases Per Capita, RegionName, CountryCode, StringencyIndexForDisplay, GovernmentResponseIndexForDisplay, ContainmentHealthIndexForDisplay, EconomicSupportIndexForDisplay]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking there is no null values in the new  combined df\n",
    "temp = covid_combined_df[covid_combined_df.isnull().any(axis=1)]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to confirm the number of rows in our dataframes are consistent and the new df is the correct len\n",
    "len(covid_combined_df) == len(df_policy) == len(deaths_and_cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_combined_df = covid_combined_df.drop(['RegionName', 'CountryCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(covid_combined_df.columns.values)\n",
    "cols.remove('Cases Per Capita')\n",
    "cols.remove('Deaths Per Capita')\n",
    "cols.append('Cases Per Capita')\n",
    "cols.append('Deaths Per Capita')\n",
    "# cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_combined_df = covid_combined_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_location_dict(df, location_col_name):\n",
    "    location_dict ={}\n",
    "    location_num = 0\n",
    "    for locale in df[location_col_name].unique():\n",
    "        location_dict[locale] = location_num\n",
    "        location_num += 1\n",
    "    return location_dict\n",
    "\n",
    "state_dict = create_location_dict(covid_combined_df, 'State')\n",
    "# state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = covid_combined_df.copy()\n",
    "df[\"State\"].replace(state_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shrink df to start at relevant start date\n",
    "# chose 2/28/2020 b/c the first date will get removed when turning it into timeseries\n",
    "# So you will be left with 3/1/2020\n",
    "df = df[df['Date'] >= \"02/29/2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deaths = df.drop(columns='Cases Per Capita')\n",
    "df_cases = df.drop(columns='Deaths Per Capita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is from:\n",
    "#     https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n",
    "\n",
    "# from pandas import DataFrame - nw note: adj calls using pd.___ \n",
    "# from pandas import concat - nw note: adj calls using pd.___\n",
    " \n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe's for time series data\n",
    "ts_death_data = pd.DataFrame()\n",
    "ts_cases_data = pd.DataFrame()\n",
    "\n",
    "# Look at df one state at a time.\n",
    "def prep_ts(df, location_col_name, new_df):\n",
    "    for locale in df[location_col_name].unique():\n",
    "        locale_df = df[df[location_col_name] == locale]\n",
    "        locale_df = locale_df.to_numpy()\n",
    "        locale_df = series_to_supervised(locale_df)\n",
    "        new_df = pd.concat([new_df, locale_df])\n",
    "    return new_df\n",
    "\n",
    "ts_death_df = prep_ts(df_deaths, 'State', ts_death_data)\n",
    "ts_cases_df = prep_ts(df_cases, 'State', ts_cases_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renameing the columns in the time series dataframes\n",
    "def rename_cols_dict(before_df, ts_df):\n",
    "    detailed_cols_list = []\n",
    "    org_cols = before_df.columns\n",
    "    for i in [\"(t-1)\",\"(t)\"]:\n",
    "        for col in org_cols:\n",
    "            detailed_cols_list.append(col+i)\n",
    "    update_cols_dict = dict(zip(ts_df.columns, detailed_cols_list))\n",
    "    return update_cols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once\n",
    "ts_death_df.rename(rename_cols_dict(df_deaths, ts_death_df), axis=1, inplace=True)\n",
    "ts_death_df.reset_index(inplace=True)\n",
    "ts_cases_df.rename(rename_cols_dict(df_deaths, ts_cases_df), axis=1, inplace=True)\n",
    "ts_cases_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOULD THE DATE COLUMNS BE REMOVED?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next i need to split data into train and test - NEED TO DO FOR CASES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part down was only done for deaths need to do the same for cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for ts_death_df\n",
    "\n",
    "# last 5 days of each month to be used for test\n",
    "march_test_rows = list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"03/27/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"03/31/2020\")].index)\n",
    "april_test_rows = list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"04/26/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"04/30/2020\")].index)\n",
    "may_test_rows = list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"05/27/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"05/31/2020\")].index)\n",
    "june_test_rows = list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"06/26/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"06/30/2020\")].index)\n",
    "july_test_rows = list(list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"07/27/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"07/31/2020\")].index))\n",
    "august_test_rows = list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"08/27/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"08/31/2020\")].index)\n",
    "sept_test_rows = list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"09/26/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"09/30/2020\")].index)\n",
    "oct_test_rows = list(ts_death_df.loc[(ts_death_df['Date(t)'] >= \"10/22/2020\") \n",
    "                                       & (ts_death_df['Date(t)'] <= \"10/26/2020\")].index)\n",
    "test_indices = march_test_rows + april_test_rows + may_test_rows + june_test_rows \\\n",
    "                + july_test_rows + august_test_rows + sept_test_rows + oct_test_rows\n",
    "# test_indices\n",
    "\n",
    "\n",
    "## If I only use one day per month to train\n",
    "# march_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"03/31/2020\"].index)\n",
    "# april_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"04/30/2020\"].index)\n",
    "# may_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"05/31/2020\"].index)\n",
    "# june_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"06/30/20200\"].index)\n",
    "# july_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"07/31/2020\"].index)\n",
    "# august_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"08/31/20200\"].index)\n",
    "# sept_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"09/30/20200\"].index)\n",
    "# oct_test_rows=list(ts_death_df[ts_death_df[\"Date(t)\"]== \"10/26/20200\"].index)\n",
    "# test_indices = march_test_rows + april_test_rows + may_test_rows + june_test_rows \\\n",
    "#                 + july_test_rows + august_test_rows + sept_test_rows + oct_test_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_train = ts_death_df[~ts_death_df.index.isin(test_indices)]\n",
    "death_test = ts_death_df[ts_death_df.index.isin(test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove the dates because they will cause the below error\n",
    "# TypeError: float() argument must be a string or a number, not 'Timestamp'\n",
    "death_train = death_train.drop(['index', \"Date(t-1)\", \"Date(t)\"], axis=1)\n",
    "death_test = death_test.drop(['index', \"Date(t-1)\", \"Date(t)\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_train_x = death_train.values[: , :-1] \n",
    "death_train_y = death_train.values[: , -1]\n",
    "death_test_x = death_test.values[: , :-1] \n",
    "death_test_y = death_test.values[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_train_x = death_train_x.reshape((death_train_x.shape[0], 1, death_train_x.shape[1]))\n",
    "death_test_x = death_test_x.reshape((death_test_x.shape[0], 1, death_test_x.shape[1]))\n",
    "\n",
    "death_train_x = np.asarray(death_train_x).astype(np.float32)\n",
    "death_train_y = np.asarray(death_train_y).astype(np.float32)\n",
    "death_test_x = np.asarray(death_test_x).astype(np.float32)\n",
    "death_test_y = np.asarray(death_test_y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 4ms/step - loss: 8.8370e-05 - val_loss: 2.1581e-06\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 2.3011e-06 - val_loss: 1.2661e-06\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 1.4361e-06 - val_loss: 8.2722e-07\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 9.6899e-07 - val_loss: 5.9586e-07\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.8692e-07 - val_loss: 4.6501e-07\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 5.3736e-07 - val_loss: 3.9648e-07\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 4.3538e-07 - val_loss: 3.3827e-07\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 3.6563e-07 - val_loss: 3.0454e-07\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 3.2292e-07 - val_loss: 2.6224e-07\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 2.8506e-07 - val_loss: 2.4026e-07\n",
      "65/65 [==============================] - 0s 761us/step - loss: 2.4026e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4025999323384895e-07"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_num = 12\n",
    "dense_1 = 21\n",
    "dense_2 = 7\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_num, input_shape = (death_train_x.shape[1], death_train_x.shape[2])))\n",
    "model.add(Dense(dense_1, activation=\"relu\"))\n",
    "model.add(Dense(dense_2, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "                    \n",
    "model.compile(optimizer='adam', loss='mse',)\n",
    "\n",
    "fit=model.fit(\n",
    "      death_train_x,\n",
    "      death_train_y,\n",
    "      epochs=epochs,\n",
    "      validation_data=(death_test_x, death_test_y),\n",
    "      batch_size=batch_size,)\n",
    "\n",
    "model.evaluate(death_test_x, death_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit439ea6fc334741b3853c15bd9125142c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
